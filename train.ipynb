{
 "metadata": {
  "name": "train"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.path.insert(0, 'webpager/')\n",
      "\n",
      "import os\n",
      "from os.path import join\n",
      "import posixpath\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.pipeline import FeatureUnion\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "from webpager.features import HtmlFeaturesExtractor, AnchorTransformers\n",
      "\n",
      "def tagged_data(folder):\n",
      "    for fname in os.listdir(folder):\n",
      "        path = os.path.join(folder, fname)\n",
      "        with open(path, 'r') as f:\n",
      "            yield path, f.read()\n",
      "\n",
      "def get_original_urls(fname):\n",
      "    return dict([str(i+1), line.strip()] for i, line in enumerate(open(fname)))\n",
      "\n",
      "def show_most_informative_features(vectorizer, clf, n=20):\n",
      "    c_f = sorted(zip(clf.coef_[0], vectorizer.get_feature_names()))\n",
      "    top = zip(c_f[:n], c_f[:-(n+1):-1])\n",
      "    for (c1,f1),(c2,f2) in top:\n",
      "        print \"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (c1,f1,c2,f2)\n",
      "\n",
      "htmlFeatGen = HtmlFeaturesExtractor()\n",
      "anchorFeatGen = FeatureUnion(AnchorTransformers)\n",
      "base_urls = get_original_urls('corpus/list.txt')\n",
      "documents = []\n",
      "labels = []\n",
      "\n",
      "for path, html in tagged_data('corpus/annotated'):\n",
      "    _id = posixpath.split(path)[1].split('.')[0]\n",
      "    x = (html, base_urls[_id])\n",
      "    anchors_, labels_ = htmlFeatGen.fit_transform(x, encoding='utf8')\n",
      "    documents.extend([(a, base_urls[_id]) for a in anchors_])\n",
      "    labels.extend(labels_)\n",
      "\n",
      "train_anchors, test_anchors, train_labels, test_labels = train_test_split(documents, labels, \\\n",
      "                                                                          test_size=0.25, random_state=42)\n",
      "train_documents = anchorFeatGen.fit_transform(train_anchors, y=train_labels)\n",
      "test_documents = anchorFeatGen.transform(test_anchors)\n",
      "\n",
      "clf = LogisticRegression(tol=1e-8, penalty='l2', C=7, class_weight='auto')\n",
      "clf.fit(train_documents, train_labels)\n",
      "\n",
      "predicted = clf.predict(test_documents)\n",
      "print '# train documents', train_documents.shape[0]\n",
      "print '# test documents', test_documents.shape[0]\n",
      "print 'confusion matrix:'\n",
      "print confusion_matrix(test_labels, predicted)\n",
      "print 'accuracy', accuracy_score(test_labels, predicted)\n",
      "print 'precision', precision_score(test_labels, predicted)\n",
      "print 'recall', recall_score(test_labels, predicted)\n",
      "\n",
      "show_most_informative_features(anchorFeatGen, clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joblib.dump(anchorFeatGen, join('webpager', 'models', 'anchorFeatGen.joblib.pkl'), compress=9)\n",
      "joblib.dump(clf, join('webpager', 'models', 'clf.joblib.pkl'), compress=9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}